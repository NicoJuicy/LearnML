# Datasets

Here is a collection of some resources for ML datasets.

[Google Dataset Search](https://datasetsearch.research.google.com)

[HuggingFace Datasets](https://github.com/huggingface/datasets)

[The Best Data is Free Data](https://towardsdatascience.com/the-best-data-is-free-data-of-course-b88230b5b47f)


### [Internet Archive](https://web.archive.org)

Many developers are too quick to choose web crawling as an option to collect data when there are easier, more ethical resources available such as the internet archive. 

The Internet Archive has been archiving the web for 20 years and has preserved billions of webpages from millions of websites. 


### [Read Datasets with URL in Python](https://towardsdatascience.com/dont-download-read-datasets-with-url-in-python-8245a5eaa919)

A tutorial to read UCI datasets without downloading them locally in any format

This tutorial explains how you can read five different types of data file format: data, csv, arff, zip, and rar

### [How to generate dummy data in Python](https://towardsdatascience.com/how-to-generate-dummy-data-in-python-a05bce24a6c6)


How to generate fake data using the Faker library. 

### [ML Cheatsheet Dataset List](https://ml-cheatsheet.readthedocs.io/en/latest/datasets.html)

List of public datasets in computer vision, NLP, and more.


## ML Dataets

### [7 Top Open Source Datasets to Train Natural Language Processing (NLP) & Text Models](https://www.kdnuggets.com/2021/11/top-open-source-datasets-nlp.html)

One of the first steps you need to take is training your NLP model on datasets. Creating your own dataset is a lot of work and actually unnecessary when just starting out.

There are many open source datasets available but keep in mind that open-source datasets are not without their problems. Unfortunately, you have to deal with bias, incomplete data, and a slew of other concerns when just grabbing any old dataset to test on.

There are a couple of places online that do a great job of curating datasets to make it easier to find what you're looking for:

- [Papers With Code](https://paperswithcode.com/datasets) - Nearly 5,000 machine learning datasets are categorized and easy to find.

- [Hugging Face](https://huggingface.co/datasets) -  A great site to find datasets focused on audio, text, speech, and other datasets specifically targeting NLP.

In addition, the following is a list of some of the best open-source datasets to start learning NLP:


### [huggingface](https://github.com/huggingface/datasets)

Datasets is a lightweight library providing two main features:

- one-line dataloaders for many public datasets: one liners to download and pre-process any of the number of datasets major public datasets (in 467 languages and dialects!) provided on the HuggingFace Datasets Hub.

- efficient data pre-processing: simple, fast and reproducible data pre-processing for the above public datasets as well as your own local datasets in CSV/JSON/text. 



## Computer Vision Datasets

### [Open Source Datasets for Computer Vision](https://www.kdnuggets.com/2021/08/open-source-datasets-computer-vision.html)

This article discuses some of the popular datasets used in the Deep Learning (DL) to train state-of-the-art ML systems for CV tasks.


### [A Systematic Collection of Medical Image Datasets for Deep Learning](https://arxiv.org/abs/2106.12864)

This paper has three purposes: 

1) to provide a most up to date and complete list that can be used as a universal reference to easily find the datasets for clinical image analysis

2) to guide researchers on the methodology to test and evaluate their methods' performance and robustness on relevant datasets

3) to provide a route to relevant algorithms for the relevant medical topics, and challenge leaderboards.

### [medical-imaging-datasets](https://github.com/sfikas/medical-imaging-datasets)

A list of medical imaging datasets.



## Natural Language Processing Datasets

### [Datasets for Natural Language Processing](https://machinelearningmastery.com/datasets-natural-language-processing/)

You need datasets to practice on when getting started with deep learning for natural language processing tasks.

It is better to use small datasets that you can download quickly and do not take too long to fit models. Further, it is also helpful to use standard datasets that are well understood and widely used so that you can compare your results to see if you are making progress.

In this post, you will discover a suite of standard datasets for natural language processing tasks that you can use when getting started with deep learning.

This post is divided into 7 parts:

1. Text Classification
2. Language Modeling
3. Image Captioning
4. Machine Translation
5. Question Answering
6. Speech Recognition
7. Document Summarization

### [nlp-datasets](https://github.com/niderhoff/nlp-datasets)

Alphabetical list of free/public domain datasets with text data for use in Natural Language Processing (NLP). Most stuff here is just raw unstructured text data, if you are looking for annotated corpora or Treebanks refer to the sources at the bottom.

### [20 Open Datasets for Natural Language Processing](https://medium.com/@ODSC/20-open-datasets-for-natural-language-processing-538fbfaf8e38)


Natural language processing is a significant part of machine learning use cases, but it requires a lot of data and some deftly handled training. 

Here are 20 more great datasets for NLP use 

### [25 Excellent Machine Learning Open Datasets](https://opendatascience.com/25-excellent-machine-learning-open-datasets/)

Here we list Amazon Reviews and Wikipedia Links for general NLP and the Standford Sentiment Treebank and Twitter US Airlines Reviews specifically for sentiment analysis. 

